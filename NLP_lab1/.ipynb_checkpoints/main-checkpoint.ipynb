{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990d78bf-a7d6-49a9-8cef-78d5d7773cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ayanami/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ayanami/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ayanami/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer as wnl\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.corpus import stopwords\n",
    "snow_stemmer = SnowballStemmer((\"russian\"))\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704e0c7e-2bc9-4b5d-8b04-3b2e7952f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "    return list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5eb34f-1521-4c80-aea3-a9c65e353a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text: str) -> dict[int]:\n",
    "    vector = {i + 1: word for i, word in enumerate(text)}\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fb0836-7d36-4863-ba95-304ce685e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_and_stemming(text: str) -> list[str]:\n",
    "    tokens = wt(text)\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    lem_text = [wnl().lemmatize(token, pos='v') for token in filtered_tokens]\n",
    "    print(f\"Лематизация текста:\\n {lem_text}\\n\")\n",
    "    stem_text = [snow_stemmer.stem(token) for token in lem_text]\n",
    "    print(f\"Стемминг текста:\\n {stem_text}\\n\")\n",
    "    result = ''.join(stem_text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baede161-5351-4023-95f3-99c6161505b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лематизация текста:\n",
      " ['nltk', '(', 'Natural', 'Language', 'ToolKit', ')', '—', 'пакет', 'библиотек', 'программ', 'символьной', 'статистической', 'обработки', 'естественного', 'языка', ',', 'написанных', 'языке', 'программирования', 'Python', '.', 'Сопровождается', 'обширной', 'документацией', ',', 'включая', 'книгу', 'объяснением', 'основных', 'концепций', ',', 'стоящих', 'теми', 'задачами', 'обработки', 'естественного', 'языка', ',', 'которые', 'выполнять', 'помощью', 'NLTK', '.']\n",
      "\n",
      "Стемминг текста:\n",
      " ['nltk', '(', 'Natural', 'Language', 'ToolKit', ')', '—', 'пакет', 'библиотек', 'программ', 'символьн', 'статистическ', 'обработк', 'естествен', 'язык', ',', 'написа', 'язык', 'программирован', 'Python', '.', 'сопровожда', 'обширн', 'документац', ',', 'включ', 'книг', 'объяснен', 'основн', 'концепц', ',', 'стоя', 'тем', 'задач', 'обработк', 'естествен', 'язык', ',', 'котор', 'выполня', 'помощ', 'NLTK', '.']\n",
      "\n",
      "Токенизация преобразованного текста:\n",
      " ['n', 'l', 't', 'k', '(', 'N', 'a', 't', 'u', 'r', 'a', 'l', 'L', 'a', 'n', 'g', 'u', 'a', 'g', 'e', 'T', 'o', 'o', 'l', 'K', 'i', 't', ')', '—', 'п', 'а', 'к', 'е', 'т', 'б', 'и', 'б', 'л', 'и', 'о', 'т', 'е', 'к', 'п', 'р', 'о', 'г', 'р', 'а', 'м', 'м', 'с', 'и', 'м', 'в', 'о', 'л', 'ь', 'н', 'с', 'т', 'а', 'т', 'и', 'с', 'т', 'и', 'ч', 'е', 'с', 'к', 'о', 'б', 'р', 'а', 'б', 'о', 'т', 'к', 'е', 'с', 'т', 'е', 'с', 'т', 'в', 'е', 'н', 'я', 'з', 'ы', 'к', ',', 'н', 'а', 'п', 'и', 'с', 'а', 'я', 'з', 'ы', 'к', 'п', 'р', 'о', 'г', 'р', 'а', 'м', 'м', 'и', 'р', 'о', 'в', 'а', 'н', 'P', 'y', 't', 'h', 'o', 'n', '.', 'с', 'о', 'п', 'р', 'о', 'в', 'о', 'ж', 'д', 'а', 'о', 'б', 'ш', 'и', 'р', 'н', 'д', 'о', 'к', 'у', 'м', 'е', 'н', 'т', 'а', 'ц', ',', 'в', 'к', 'л', 'ю', 'ч', 'к', 'н', 'и', 'г', 'о', 'б', 'ъ', 'я', 'с', 'н', 'е', 'н', 'о', 'с', 'н', 'о', 'в', 'н', 'к', 'о', 'н', 'ц', 'е', 'п', 'ц', ',', 'с', 'т', 'о', 'я', 'т', 'е', 'м', 'з', 'а', 'д', 'а', 'ч', 'о', 'б', 'р', 'а', 'б', 'о', 'т', 'к', 'е', 'с', 'т', 'е', 'с', 'т', 'в', 'е', 'н', 'я', 'з', 'ы', 'к', ',', 'к', 'о', 'т', 'о', 'р', 'в', 'ы', 'п', 'о', 'л', 'н', 'я', 'п', 'о', 'м', 'о', 'щ', 'N', 'L', 'T', 'K', '.']\n",
      "\n",
      "Векторизация преобразованного текста:\n",
      " {1: 'n', 2: 'l', 3: 't', 4: 'k', 5: '(', 6: 'N', 7: 'a', 8: 't', 9: 'u', 10: 'r', 11: 'a', 12: 'l', 13: 'L', 14: 'a', 15: 'n', 16: 'g', 17: 'u', 18: 'a', 19: 'g', 20: 'e', 21: 'T', 22: 'o', 23: 'o', 24: 'l', 25: 'K', 26: 'i', 27: 't', 28: ')', 29: '—', 30: 'п', 31: 'а', 32: 'к', 33: 'е', 34: 'т', 35: 'б', 36: 'и', 37: 'б', 38: 'л', 39: 'и', 40: 'о', 41: 'т', 42: 'е', 43: 'к', 44: 'п', 45: 'р', 46: 'о', 47: 'г', 48: 'р', 49: 'а', 50: 'м', 51: 'м', 52: 'с', 53: 'и', 54: 'м', 55: 'в', 56: 'о', 57: 'л', 58: 'ь', 59: 'н', 60: 'с', 61: 'т', 62: 'а', 63: 'т', 64: 'и', 65: 'с', 66: 'т', 67: 'и', 68: 'ч', 69: 'е', 70: 'с', 71: 'к', 72: 'о', 73: 'б', 74: 'р', 75: 'а', 76: 'б', 77: 'о', 78: 'т', 79: 'к', 80: 'е', 81: 'с', 82: 'т', 83: 'е', 84: 'с', 85: 'т', 86: 'в', 87: 'е', 88: 'н', 89: 'я', 90: 'з', 91: 'ы', 92: 'к', 93: ',', 94: 'н', 95: 'а', 96: 'п', 97: 'и', 98: 'с', 99: 'а', 100: 'я', 101: 'з', 102: 'ы', 103: 'к', 104: 'п', 105: 'р', 106: 'о', 107: 'г', 108: 'р', 109: 'а', 110: 'м', 111: 'м', 112: 'и', 113: 'р', 114: 'о', 115: 'в', 116: 'а', 117: 'н', 118: 'P', 119: 'y', 120: 't', 121: 'h', 122: 'o', 123: 'n', 124: '.', 125: 'с', 126: 'о', 127: 'п', 128: 'р', 129: 'о', 130: 'в', 131: 'о', 132: 'ж', 133: 'д', 134: 'а', 135: 'о', 136: 'б', 137: 'ш', 138: 'и', 139: 'р', 140: 'н', 141: 'д', 142: 'о', 143: 'к', 144: 'у', 145: 'м', 146: 'е', 147: 'н', 148: 'т', 149: 'а', 150: 'ц', 151: ',', 152: 'в', 153: 'к', 154: 'л', 155: 'ю', 156: 'ч', 157: 'к', 158: 'н', 159: 'и', 160: 'г', 161: 'о', 162: 'б', 163: 'ъ', 164: 'я', 165: 'с', 166: 'н', 167: 'е', 168: 'н', 169: 'о', 170: 'с', 171: 'н', 172: 'о', 173: 'в', 174: 'н', 175: 'к', 176: 'о', 177: 'н', 178: 'ц', 179: 'е', 180: 'п', 181: 'ц', 182: ',', 183: 'с', 184: 'т', 185: 'о', 186: 'я', 187: 'т', 188: 'е', 189: 'м', 190: 'з', 191: 'а', 192: 'д', 193: 'а', 194: 'ч', 195: 'о', 196: 'б', 197: 'р', 198: 'а', 199: 'б', 200: 'о', 201: 'т', 202: 'к', 203: 'е', 204: 'с', 205: 'т', 206: 'е', 207: 'с', 208: 'т', 209: 'в', 210: 'е', 211: 'н', 212: 'я', 213: 'з', 214: 'ы', 215: 'к', 216: ',', 217: 'к', 218: 'о', 219: 'т', 220: 'о', 221: 'р', 222: 'в', 223: 'ы', 224: 'п', 225: 'о', 226: 'л', 227: 'н', 228: 'я', 229: 'п', 230: 'о', 231: 'м', 232: 'о', 233: 'щ', 234: 'N', 235: 'L', 236: 'T', 237: 'K', 238: '.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"res/text.txt\", 'r') as file:\n",
    "    text = file.read().replace('\\n', '')\n",
    "result = lemmatize_and_stemming(text)\n",
    "tokenized_text = tokenize(result)\n",
    "print(f\"Токенизация преобразованного текста:\\n {tokenized_text}\\n\")\n",
    "\n",
    "vectorize_text = vectorize(result)\n",
    "print(f\"Векторизация преобразованного текста:\\n {vectorize_text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
