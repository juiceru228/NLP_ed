{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "088557a6-a47a-4dc5-af05-292237acbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471b7886-24c8-4ba1-8be9-627a5e059e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class SimpleGPT:\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, seq_length: int):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.token_embed = np.random.randn(vocab_size, embed_dim) * 0.1\n",
    "        self.pos_embed = np.random.randn(seq_length, embed_dim) * 0.1\n",
    "        \n",
    "        self.Wq = np.random.randn(embed_dim, embed_dim) * 0.1\n",
    "        self.Wk = np.random.randn(embed_dim, embed_dim) * 0.1\n",
    "        self.Wv = np.random.randn(embed_dim, embed_dim) * 0.1\n",
    "        \n",
    "        self.W_out = np.random.randn(embed_dim, vocab_size) * 0.1\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "        return exp_x / exp_x.sum(axis=-1, keepdims=True)\n",
    "    \n",
    "    def attention(self, x):\n",
    "        Q = np.dot(x, self.Wq)\n",
    "        K = np.dot(x, self.Wk)\n",
    "        V = np.dot(x, self.Wv)\n",
    "        \n",
    "        scores = np.dot(Q, K.T) / np.sqrt(self.embed_dim)\n",
    "        attn = self.softmax(scores)\n",
    "        return np.dot(attn, V)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        token_emb = self.token_embed[inputs]\n",
    "        pos_emb = self.pos_embed[:len(inputs)]\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.attention(x)\n",
    "        logits = np.dot(x, self.W_out)\n",
    "        return self.softmax(logits[-1])\n",
    "    \n",
    "    def backward(self, inputs, x, Q, K, V, attn, attn_output, probs, target, lr):\n",
    "        # Градиенты логитов\n",
    "        d_logits = probs.copy()\n",
    "        d_logits[target] -= 1\n",
    "\n",
    "        d_W_out = np.outer(attn_output[-1], d_logits)\n",
    "        d_attn_out = np.zeros_like(attn_output)\n",
    "        d_attn_out[-1] = np.dot(self.W_out, d_logits)\n",
    "\n",
    "        d_V = np.dot(attn.T, d_attn_out)\n",
    "        d_attn = np.dot(d_attn_out, V.T)\n",
    "\n",
    "        d_scores = attn * (d_attn - (attn * d_attn).sum(axis=1, keepdims=True))\n",
    "        d_scores /= np.sqrt(self.embed_dim)\n",
    "\n",
    "        d_Q = np.dot(d_scores, K)\n",
    "        d_K = np.dot(d_scores.T, Q)\n",
    "\n",
    "        d_Wq = np.dot(x.T, d_Q)\n",
    "        d_Wk = np.dot(x.T, d_K)\n",
    "        d_Wv = np.dot(x.T, d_V)\n",
    "\n",
    "        d_emb = np.dot(d_Q, self.Wq.T) + np.dot(d_K, self.Wk.T) + np.dot(d_V, self.Wv.T)\n",
    "\n",
    "        self.W_out -= lr * d_W_out\n",
    "        self.Wq -= lr * d_Wq\n",
    "        self.Wk -= lr * d_Wk\n",
    "        self.Wv -= lr * d_Wv\n",
    "        self.token_embed[inputs] -= lr * d_emb\n",
    "        self.pos_embed[:len(inputs)] -= lr * d_emb\n",
    "    def train_step(self, inputs, target, lr):\n",
    "        token_emb = self.token_embed[inputs]\n",
    "        pos_emb = self.pos_embed[:len(inputs)]\n",
    "        x = token_emb + pos_emb\n",
    "\n",
    "        Q = np.dot(x, self.Wq)\n",
    "        K = np.dot(x, self.Wk)\n",
    "        V = np.dot(x, self.Wv)\n",
    "\n",
    "        scores = np.dot(Q, K.T) / np.sqrt(self.embed_dim)\n",
    "        attn = self.softmax(scores)\n",
    "        attn_output = np.dot(attn, V)\n",
    "\n",
    "        logits = np.dot(attn_output, self.W_out)\n",
    "        probs = self.softmax(logits[-1])\n",
    "\n",
    "        loss = -np.log(probs[target])\n",
    "\n",
    "        self.backward(inputs, x, Q, K, V, attn, attn_output, probs, target, lr)\n",
    "\n",
    "        return loss\n",
    "    def generate(self, start_seq, char_to_idx, idx_to_char, max_new_tokens):\n",
    "        generated = start_seq[:]\n",
    "        for _ in range(max_new_tokens):\n",
    "            context = generated[-self.seq_length:]\n",
    "            if len(context) < self.seq_length:\n",
    "                context = [0] * (self.seq_length - len(context)) + context\n",
    "            probs = self.forward(context)\n",
    "            next_token = np.argmax(probs)\n",
    "            generated.append(next_token)\n",
    "        return ''.join([idx_to_char[i] for i in generated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0df3f3-fdc3-49a3-b968-a24d4036dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(text, char_to_idx):\n",
    "    return [char_to_idx[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95a4d2c-7247-4701-be73-1f46c2f1193b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.4177491331244263\n",
      "Epoch 10, Loss: 0.8090330833228876\n",
      "Epoch 20, Loss: 0.5436244989883153\n",
      "Epoch 30, Loss: 0.46484287366960636\n",
      "Epoch 40, Loss: 0.4575337757083219\n",
      "Epoch 50, Loss: 0.42037114036152246\n",
      "Epoch 60, Loss: 0.37320764808148277\n",
      "Epoch 70, Loss: 0.38295748188304407\n",
      "Epoch 80, Loss: 0.34607843141582834\n",
      "Epoch 90, Loss: 0.3328544664190199\n",
      "Epoch 99, Loss: 0.3256029507149844\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"«Текст» — российский криминально-драматический психологический триллер режиссёра Клима Шипенко,\n",
    "экранизация романа-бестселлера «Текст» (2017) писателя Дмитрия Глуховского, который сам адаптировал свой роман в киносценарий.\n",
    "Фильм рассказывает о бывшем заключённом Илье Горюнове, который мстит полицейскому Петру Хазину, подбросившему ему наркотики,\n",
    "и в результате получает доступ к его смартфону. Вместе с ним он получает доступ и к жизни героя, и на время становится для всех Хазиным,\n",
    "отправляя сообщения его начальству, родителям и девушке Нине, в которую влюбляется и сам.\"\"\"*500\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "char_to_idx = {c:i for i,c in enumerate(chars)}\n",
    "idx_to_char = {i:c for c,i in char_to_idx.items()}\n",
    "seq_length = 5\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(len(text) - seq_length):\n",
    "    X.append(text_to_indices(text[i:i+seq_length], char_to_idx))\n",
    "    y.append(char_to_idx[text[i+seq_length]])\n",
    "\n",
    "model = SimpleGPT(vocab_size, embed_dim=16, seq_length=seq_length)\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.0005\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, target in zip(X, y):\n",
    "        loss = model.train_step(inputs, target, learning_rate)\n",
    "        total_loss += loss\n",
    "    if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss/len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df04d1c5-fb98-4033-8417-b2b9e20cc086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "Текст» — российский триоваляя в киносценартфону. Вместе с н вуПеру наркотики,\n",
      "ровившему ему наркотики,\n",
      "ро\n"
     ]
    }
   ],
   "source": [
    "start_text = \"Текст\"\n",
    "test_input = [char_to_idx[c] for c in start_text]\n",
    "generated_text = model.generate(test_input, char_to_idx, idx_to_char, max_new_tokens=100)\n",
    "print(f\"Generated text:\\n{generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d06a505-1605-4f51-afb6-3e47b643579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "Петру Хазиным,\n",
      "отправучс.ческо агояоммес адаптироваляя в киносценартфону. Вместе с н вуПеру наркотики,\n",
      "ро\n"
     ]
    }
   ],
   "source": [
    "start_text = \"Петру\"\n",
    "test_input = [char_to_idx[c] for c in start_text]\n",
    "generated_text = model.generate(test_input, char_to_idx, idx_to_char, max_new_tokens=100)\n",
    "print(f\"Generated text:\\n{generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c05aa46-56ef-48eb-878d-07b65cb77b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "Клима Шипенко о,\n",
      "бщнатсИльтьте ну Нине, в который.омус агояоммес адаптироваляя в киносценартфону. Вместе \n"
     ]
    }
   ],
   "source": [
    "start_text = \"Клима\"\n",
    "test_input = [char_to_idx[c] for c in start_text]\n",
    "generated_text = model.generate(test_input, char_to_idx, idx_to_char, max_new_tokens=100)\n",
    "print(f\"Generated text:\\n{generated_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
