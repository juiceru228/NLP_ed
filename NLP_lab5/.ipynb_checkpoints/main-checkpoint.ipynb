{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76b8517-2069-49ec-94b2-c299c1eb7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab253f8e-85d9-49dc-b915-1bf7a698823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('res/bbc-text.csv')\n",
    "category_num = df['category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619dfb5b-d6f8-4d67-89f7-14bee4262da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>business</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>politics</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>politics</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>sport</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "0              tech  tv future in the hands of viewers with home th...\n",
       "1          business  worldcom boss  left books alone  former worldc...\n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3             sport  yeading face newcastle in fa cup premiership s...\n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "...             ...                                                ...\n",
       "2220       business  cars pull down us retail figures us retail sal...\n",
       "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
       "2223       politics  how political squabbles snowball it s become c...\n",
       "2224          sport  souness delight at euro progress boss graeme s...\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51aa5490-81cd-4013-b530-6ee833e860ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b1d732-5394-4855-8921-6df08f13e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    stemmed = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b20ca-5728-4742-a68a-ef66b4fb03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc7b24-04c0-40c9-9f22-a0aff775eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198d639-a74f-4554-99e0-cfa77500d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=category_num, random_state=228)\n",
    "kmeans.fit(X)\n",
    "clusters = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7e931-1e6b-4938-a7f9-99d622f3f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari = adjusted_rand_score(df['category'], clusters)\n",
    "print(f\"Adjusted Rand Index: {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e3108-ebb7-4f74-9688-9f07ecf90507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2, random_state=228)\n",
    "X_reduced = pca.fit_transform(X.toarray())\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'x': X_reduced[:, 0],\n",
    "    'y': X_reduced[:, 1],\n",
    "    'cluster': clusters,\n",
    "    'category': df['category']\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(plot_df['x'], plot_df['y'],c=plot_df['cluster'], cmap='viridis',alpha=0.6)\n",
    "\n",
    "plt.legend(*scatter.legend_elements(),\n",
    "           title=\"Кластеры\")\n",
    "plt.title(f\"Визуализация кластеров (ARI: {ari:.3f})\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cbb271-df9a-49ff-bd57-e07ad6170414",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(df['cleaned_text'], df['category'], test_size=0.3, random_state=228)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd1df4-2d0b-4666-886c-088086debc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Всего данных: {len(df)}\")\n",
    "print(f\"Тренировочные: {len(X_train)} ({len(X_train)/len(df):.0%})\")\n",
    "print(f\"Валидационные: {len(X_val)} ({len(X_val)/len(df):.0%})\")\n",
    "print(f\"Тестовые: {len(X_test)} ({len(X_test)/len(df):.0%})\")\n",
    "print(\"\\nКоличество примеров по категориям в y_train:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb527253-f7ee-4230-8bcf-70c9ddedcbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['category'])\n",
    "\n",
    "train_df = pd.DataFrame({'text': X_train, 'label': le.transform(y_train)})\n",
    "val_df = pd.DataFrame({'text': X_val, 'label': le.transform(y_val)})\n",
    "test_df = pd.DataFrame({'text': X_test, 'label': le.transform(y_test)})\n",
    "\n",
    "dataset = Dataset.from_pandas(pd.concat([train_df, val_df, test_df]))\n",
    "dataset = dataset.train_test_split(test_size=0.3, seed=228)\n",
    "val_test_split = dataset['test'].train_test_split(test_size=0.5, seed=228)\n",
    "\n",
    "dataset = {\n",
    "    'train': dataset['train'],\n",
    "    'validation': val_test_split['train'],\n",
    "    'test': val_test_split['test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019860b-5045-4ac0-99a0-430a6387b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = {k: v.map(tokenize_function, batched=True) for k, v in dataset.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f972ea-7349-45b2-934d-9ac734f12c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(le.classes_)\n",
    ").to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da840980-7ee3-4a32-9d16-55a7f7407acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(f\"\\nТочность на тесте: {test_results['eval_accuracy']:.3f}\")\n",
    "print(f\"F1-мера на тесте: {test_results['eval_f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b10ce-1333-4eea-b84a-ad27d74249d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "preds_output = trainer.predict(tokenized_datasets[\"test\"])\n",
    "y_pred = np.argmax(preds_output.predictions, axis=1)\n",
    "y_true = preds_output.label_ids\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.title(\"Матрица ошибок\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b91257-9d89-42ef-8c27-9fcc1d49720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "text = f\"\"\"\n",
    "**Вывод:**\n",
    "\n",
    "- Для обучения, валидации, тестирования была использована дообученная модель ***bert-base-uncased***.\n",
    "- Точность ***accuracy = {test_results['eval_accuracy']:.3f}***, как и ***f1 = {test_results['eval_f1']:.3f}***, говорит о том, что модель с задачей классификации справилась как минимум неплохо.\n",
    "- Низкий ***loss***, стремящийся к ***{test_results['eval_loss']:.3f}***, подтверждает хорошее обучение.\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
