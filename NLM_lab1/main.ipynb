{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990d78bf-a7d6-49a9-8cef-78d5d7773cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ayanami/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ayanami/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer as ps\n",
    "from nltk.stem import WordNetLemmatizer as wnl\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704e0c7e-2bc9-4b5d-8b04-3b2e7952f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "    return list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5eb34f-1521-4c80-aea3-a9c65e353a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text: str) -> dict[int]:\n",
    "    vector = {i + 1: word for i, word in enumerate(text)}\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fb0836-7d36-4863-ba95-304ce685e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_and_stemming(text: str) -> list[str]:\n",
    "    tokens = wt(text)\n",
    "    lem_text = [wnl().lemmatize(token, pos='v') for token in tokens]\n",
    "    stem_text = [ps().stem(token) for token in lem_text]\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baede161-5351-4023-95f3-99c6161505b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токенизация преобразованного текста:\n",
      " ['natur', 'languag', 'toolkitnltk', 'be', 'a', 'lead', 'platform', 'for', 'build', 'python', 'program', 'to', 'work', 'with', 'human', 'languag', 'data', '.', 'it', 'provid', 'easy-to-us', 'interfac', 'to', 'over', '50', 'corpora', 'and', 'lexic', 'resourc', 'such', 'as', 'wordnet', ',', 'along', 'with', 'a', 'suit', 'of', 'text', 'process', 'librari', 'for', 'classif', ',', 'token', ',', 'stem', ',', 'tag', ',', 'pars', ',', 'and', 'semant', 'reason', ',', 'wrapper', 'for', 'industrial-strength', 'nlp', 'librari', ',', 'and', 'an', 'activ', 'discuss', 'forum.thank', 'to', 'a', 'hands-on', 'guid', 'introduc', 'program', 'fundament', 'alongsid', 'topic', 'in', 'comput', 'linguist', ',', 'plu', 'comprehens', 'api', 'document', ',', 'nltk', 'be', 'suitabl', 'for', 'linguist', ',', 'engin', ',', 'student', ',', 'educ', ',', 'research', ',', 'and', 'industri', 'user', 'alik', '.', 'nltk', 'be', 'avail', 'for', 'window', ',', 'mac', 'os', 'x', ',', 'and', 'linux', '.', 'best', 'of', 'all', ',', 'nltk', 'be', 'a', 'free', ',', 'open', 'sourc', ',', 'community-driven', 'project.nltk', 'have', 'be', 'call', '“', 'a', 'wonder', 'tool', 'for', 'teach', ',', 'and', 'work', 'in', ',', 'comput', 'linguist', 'use', 'python', ',', '”', 'and', '“', 'an', 'amaz', 'librari', 'to', 'play', 'with', 'natur', 'language.', '”', 'natur', 'languag', 'process', 'with', 'python', 'provid', 'a', 'practic', 'introduct', 'to', 'program', 'for', 'languag', 'process', '.', 'written', 'by', 'the', 'creator', 'of', 'nltk', ',', 'it', 'guid', 'the', 'reader', 'through', 'the', 'fundament', 'of', 'write', 'python', 'program', ',', 'work', 'with', 'corpora', ',', 'categor', 'text', ',', 'analyz', 'linguist', 'structur', ',', 'and', 'more', '.', 'the', 'onlin', 'version', 'of', 'the', 'book', 'have', 'be', 'be', 'updat', 'for', 'python', '3', 'and', 'nltk', '3', '.', '(', 'the', 'origin', 'python', '2', 'version', 'be', 'still', 'avail', 'at', 'http', ':', '//www.nltk.org/book_1', '.', ')']\n",
      "\n",
      "Векторизация преобразованного текста:\n",
      " {1: 'natur', 2: 'languag', 3: 'toolkitnltk', 4: 'be', 5: 'a', 6: 'lead', 7: 'platform', 8: 'for', 9: 'build', 10: 'python', 11: 'program', 12: 'to', 13: 'work', 14: 'with', 15: 'human', 16: 'languag', 17: 'data', 18: '.', 19: 'it', 20: 'provid', 21: 'easy-to-us', 22: 'interfac', 23: 'to', 24: 'over', 25: '50', 26: 'corpora', 27: 'and', 28: 'lexic', 29: 'resourc', 30: 'such', 31: 'as', 32: 'wordnet', 33: ',', 34: 'along', 35: 'with', 36: 'a', 37: 'suit', 38: 'of', 39: 'text', 40: 'process', 41: 'librari', 42: 'for', 43: 'classif', 44: ',', 45: 'token', 46: ',', 47: 'stem', 48: ',', 49: 'tag', 50: ',', 51: 'pars', 52: ',', 53: 'and', 54: 'semant', 55: 'reason', 56: ',', 57: 'wrapper', 58: 'for', 59: 'industrial-strength', 60: 'nlp', 61: 'librari', 62: ',', 63: 'and', 64: 'an', 65: 'activ', 66: 'discuss', 67: 'forum.thank', 68: 'to', 69: 'a', 70: 'hands-on', 71: 'guid', 72: 'introduc', 73: 'program', 74: 'fundament', 75: 'alongsid', 76: 'topic', 77: 'in', 78: 'comput', 79: 'linguist', 80: ',', 81: 'plu', 82: 'comprehens', 83: 'api', 84: 'document', 85: ',', 86: 'nltk', 87: 'be', 88: 'suitabl', 89: 'for', 90: 'linguist', 91: ',', 92: 'engin', 93: ',', 94: 'student', 95: ',', 96: 'educ', 97: ',', 98: 'research', 99: ',', 100: 'and', 101: 'industri', 102: 'user', 103: 'alik', 104: '.', 105: 'nltk', 106: 'be', 107: 'avail', 108: 'for', 109: 'window', 110: ',', 111: 'mac', 112: 'os', 113: 'x', 114: ',', 115: 'and', 116: 'linux', 117: '.', 118: 'best', 119: 'of', 120: 'all', 121: ',', 122: 'nltk', 123: 'be', 124: 'a', 125: 'free', 126: ',', 127: 'open', 128: 'sourc', 129: ',', 130: 'community-driven', 131: 'project.nltk', 132: 'have', 133: 'be', 134: 'call', 135: '“', 136: 'a', 137: 'wonder', 138: 'tool', 139: 'for', 140: 'teach', 141: ',', 142: 'and', 143: 'work', 144: 'in', 145: ',', 146: 'comput', 147: 'linguist', 148: 'use', 149: 'python', 150: ',', 151: '”', 152: 'and', 153: '“', 154: 'an', 155: 'amaz', 156: 'librari', 157: 'to', 158: 'play', 159: 'with', 160: 'natur', 161: 'language.', 162: '”', 163: 'natur', 164: 'languag', 165: 'process', 166: 'with', 167: 'python', 168: 'provid', 169: 'a', 170: 'practic', 171: 'introduct', 172: 'to', 173: 'program', 174: 'for', 175: 'languag', 176: 'process', 177: '.', 178: 'written', 179: 'by', 180: 'the', 181: 'creator', 182: 'of', 183: 'nltk', 184: ',', 185: 'it', 186: 'guid', 187: 'the', 188: 'reader', 189: 'through', 190: 'the', 191: 'fundament', 192: 'of', 193: 'write', 194: 'python', 195: 'program', 196: ',', 197: 'work', 198: 'with', 199: 'corpora', 200: ',', 201: 'categor', 202: 'text', 203: ',', 204: 'analyz', 205: 'linguist', 206: 'structur', 207: ',', 208: 'and', 209: 'more', 210: '.', 211: 'the', 212: 'onlin', 213: 'version', 214: 'of', 215: 'the', 216: 'book', 217: 'have', 218: 'be', 219: 'be', 220: 'updat', 221: 'for', 222: 'python', 223: '3', 224: 'and', 225: 'nltk', 226: '3', 227: '.', 228: '(', 229: 'the', 230: 'origin', 231: 'python', 232: '2', 233: 'version', 234: 'be', 235: 'still', 236: 'avail', 237: 'at', 238: 'http', 239: ':', 240: '//www.nltk.org/book_1', 241: '.', 242: ')'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"res/text.txt\", 'r') as file:\n",
    "    text = file.read().replace('\\n', '')\n",
    "result = lemmatize_and_stemming(text)\n",
    "\n",
    "tokenized_text = tokenize(result)\n",
    "print(f\"Токенизация преобразованного текста:\\n {tokenized_text}\\n\")\n",
    "\n",
    "vectorize_text = vectorize(result)\n",
    "print(f\"Векторизация преобразованного текста:\\n {vectorize_text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
